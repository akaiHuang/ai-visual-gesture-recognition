"""
å¯æ“´å……çš„ AI æ‰‹å‹¢è­˜åˆ¥æ¨¡å‹æ¥å£

æä¾›çµ±ä¸€çš„æ¨¡å‹æ¥å£ï¼Œæ”¯æ´ä¸åŒçš„æ©Ÿå™¨å­¸ç¿’æ¨¡å‹å¯¦ä½œã€‚
"""

from abc import ABC, abstractmethod
import numpy as np
from typing import Optional, Dict, Any, List, Tuple


class GestureModel(ABC):
    """æ‰‹å‹¢è­˜åˆ¥æ¨¡å‹åŸºé¡
    
    æ‰€æœ‰æ‰‹å‹¢è­˜åˆ¥æ¨¡å‹éƒ½æ‡‰è©²ç¹¼æ‰¿æ­¤é¡ä¸¦å¯¦ä½œ predict æ–¹æ³•ã€‚
    """
    
    def __init__(self, model_path: Optional[str] = None):
        """åˆå§‹åŒ–æ¨¡å‹
        
        Args:
            model_path: æ¨¡å‹æª”æ¡ˆè·¯å¾‘ï¼ˆå¯é¸ï¼‰
        """
        self.model_path = model_path
        self.is_loaded = False
    
    @abstractmethod
    def load_model(self) -> bool:
        """è¼‰å…¥æ¨¡å‹
        
        Returns:
            æ˜¯å¦è¼‰å…¥æˆåŠŸ
        """
        pass
    
    @abstractmethod
    def predict(self, landmarks: np.ndarray) -> Dict[str, Any]:
        """é æ¸¬æ‰‹å‹¢
        
        Args:
            landmarks: æ‰‹éƒ¨é—œéµé»ï¼Œshape ç‚º (21, 3) æˆ– (21, 2)
            
        Returns:
            é æ¸¬çµæœå­—å…¸ï¼Œè‡³å°‘åŒ…å«:
            {
                'gesture': str,  # æ‰‹å‹¢åç¨±
                'confidence': float,  # ä¿¡å¿ƒåº¦ (0-1)
                'details': Any  # å…¶ä»–è©³ç´°è³‡è¨Šï¼ˆå¯é¸ï¼‰
            }
        """
        pass
    
    def preprocess(self, landmarks: np.ndarray) -> np.ndarray:
        """é è™•ç†é—œéµé»è³‡æ–™ï¼ˆå¯è¦†å¯«ï¼‰
        
        Args:
            landmarks: åŸå§‹é—œéµé»è³‡æ–™
            
        Returns:
            é è™•ç†å¾Œçš„è³‡æ–™
        """
        return landmarks


class DummyModel(GestureModel):
    """ç¤ºç¯„ç”¨çš„å‡æ¨¡å‹
    
    æ ¹æ“šæ‰‹éƒ¨ä½ç½®ç°¡å–®åˆ¤æ–·æ‰‹å‹¢ï¼ˆåƒ…ä¾›æ¸¬è©¦ï¼‰ã€‚
    """
    
    def __init__(self):
        super().__init__(model_path=None)
        self.gestures = [
            "æ¡æ‹³ ğŸ‘Š",
            "å¼µé–‹æ‰‹æŒ ğŸ–ï¸",
            "æ¯”è®š ğŸ‘",
            "æ¯” YA âœŒï¸",
            "æ¯” OK ğŸ‘Œ",
            "æŒ‡å‘ ğŸ‘‰"
        ]
    
    def load_model(self) -> bool:
        """è¼‰å…¥æ¨¡å‹ï¼ˆå‡æ¨¡å‹ç„¡éœ€è¼‰å…¥ï¼‰"""
        self.is_loaded = True
        return True
    
    def predict(self, landmarks: np.ndarray) -> Dict[str, Any]:
        """æ”¹é€²çš„è¦å‰‡å¼æ‰‹å‹¢åˆ¤æ–·
        
        ä½¿ç”¨æ›´ç²¾ç¢ºçš„æ‰‹æŒ‡å½æ›²åº¦åˆ¤æ–·ï¼Œæé«˜æº–ç¢ºç‡ã€‚
        """
        if not self.is_loaded:
            self.load_model()
        
        # è¨ˆç®—æ¯æ ¹æ‰‹æŒ‡æ˜¯å¦ä¼¸ç›´
        fingers_up = self._count_fingers(landmarks)
        
        # è¨ˆç®—æ‰‹æŒ‡å½æ›²è§’åº¦
        finger_angles = self._calculate_finger_angles(landmarks)
        
        # æ ¹æ“šæ‰‹æŒ‡ç‹€æ…‹åˆ¤æ–·æ‰‹å‹¢
        gesture, confidence = self._recognize_gesture(fingers_up, finger_angles, landmarks)
        
        return {
            'gesture': gesture,
            'confidence': confidence,
            'details': {
                'fingers_up': fingers_up,
                'finger_angles': [float(a) for a in finger_angles]
            }
        }
    
    def _count_fingers(self, landmarks: np.ndarray) -> List[bool]:
        """åˆ¤æ–·æ¯æ ¹æ‰‹æŒ‡æ˜¯å¦ä¼¸ç›´
        
        Returns:
            [æ‹‡æŒ‡, é£ŸæŒ‡, ä¸­æŒ‡, ç„¡åæŒ‡, å°æŒ‡] çš„ä¼¸ç›´ç‹€æ…‹
        """
        fingers = []
        
        # æ‹‡æŒ‡ï¼šæ¯”è¼ƒæŒ‡å°–(4)å’ŒæŒ‡æ ¹(2)çš„ x åº§æ¨™
        thumb_tip = landmarks[4]
        thumb_mcp = landmarks[2]
        thumb_extended = abs(thumb_tip[0] - thumb_mcp[0]) > 0.04
        fingers.append(thumb_extended)
        
        # å…¶ä»–å››æŒ‡ï¼šæ¯”è¼ƒæŒ‡å°–å’Œç¬¬äºŒé—œç¯€çš„ y åº§æ¨™
        finger_tips = [8, 12, 16, 20]  # é£ŸæŒ‡ã€ä¸­æŒ‡ã€ç„¡åæŒ‡ã€å°æŒ‡
        finger_pips = [6, 10, 14, 18]  # å°æ‡‰çš„ç¬¬äºŒé—œç¯€
        
        for tip_idx, pip_idx in zip(finger_tips, finger_pips):
            extended = landmarks[tip_idx][1] < landmarks[pip_idx][1]
            fingers.append(extended)
        
        return fingers
    
    def _calculate_finger_angles(self, landmarks: np.ndarray) -> List[float]:
        """è¨ˆç®—æ¯æ ¹æ‰‹æŒ‡çš„å½æ›²è§’åº¦"""
        angles = []
        
        # è¨ˆç®—äº”æ ¹æ‰‹æŒ‡çš„è§’åº¦
        finger_joints = [
            [1, 2, 4],    # æ‹‡æŒ‡
            [5, 6, 8],    # é£ŸæŒ‡
            [9, 10, 12],  # ä¸­æŒ‡
            [13, 14, 16], # ç„¡åæŒ‡
            [17, 18, 20]  # å°æŒ‡
        ]
        
        for joints in finger_joints:
            a = landmarks[joints[0]][:2]
            b = landmarks[joints[1]][:2]
            c = landmarks[joints[2]][:2]
            
            ba = a - b
            bc = c - b
            
            cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc) + 1e-6)
            angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))
            angles.append(np.degrees(angle))
        
        return angles
    
    def _recognize_gesture(self, fingers_up: List[bool], finger_angles: List[float], landmarks: np.ndarray) -> Tuple[str, float]:
        """æ ¹æ“šæ‰‹æŒ‡ç‹€æ…‹è­˜åˆ¥æ‰‹å‹¢"""
        
        # æ¡æ‹³ï¼šæ‰€æœ‰æ‰‹æŒ‡å½æ›²
        if not any(fingers_up):
            return "æ¡æ‹³ ğŸ‘Š", 0.95
        
        # å¼µé–‹æ‰‹æŒï¼šæ‰€æœ‰æ‰‹æŒ‡ä¼¸ç›´
        if all(fingers_up):
            return "å¼µé–‹æ‰‹æŒ ğŸ–ï¸", 0.95
        
        # æ¯”è®šï¼šåªæœ‰æ‹‡æŒ‡ä¼¸ç›´
        if fingers_up[0] and not any(fingers_up[1:]):
            return "æ¯”è®š ğŸ‘", 0.95
        
        # æ¯” YAï¼šé£ŸæŒ‡å’Œä¸­æŒ‡ä¼¸ç›´
        if fingers_up[1] and fingers_up[2] and not fingers_up[3] and not fingers_up[4]:
            return "æ¯” YA âœŒï¸", 0.90
        
        # æ¯” OKï¼šæ‹‡æŒ‡å’Œé£ŸæŒ‡æ¥è§¸å½¢æˆåœ“åœˆ
        thumb_tip = landmarks[4]
        index_tip = landmarks[8]
        distance = np.linalg.norm(thumb_tip[:2] - index_tip[:2])
        if distance < 0.05 and fingers_up[2] and fingers_up[3] and fingers_up[4]:
            return "æ¯” OK ğŸ‘Œ", 0.85
        
        # æŒ‡å‘ï¼šåªæœ‰é£ŸæŒ‡ä¼¸ç›´
        if fingers_up[1] and not fingers_up[2] and not fingers_up[3] and not fingers_up[4]:
            return "æŒ‡å‘ ğŸ‘‰", 0.90
        
        # å°æŒ‡ä¼¸ç›´ (æ–æ»¾æ‰‹å‹¢æˆ–æ‰“æ‹›å‘¼)
        if fingers_up[4] and not fingers_up[2] and not fingers_up[3]:
            return "æ–æ»¾ ğŸ¤˜", 0.85
        
        # ä¸‰æ ¹æ‰‹æŒ‡
        if sum(fingers_up[1:]) == 3:
            return "ä¸‰ â˜ï¸", 0.80
        
        # é è¨­ï¼šæœªçŸ¥æ‰‹å‹¢
        return "æœªçŸ¥ ğŸ¤”", 0.50


class MLModel(GestureModel):
    """æ©Ÿå™¨å­¸ç¿’æ¨¡å‹æ¥å£ï¼ˆé ç•™ï¼‰
    
    å¯ä»¥åœ¨é€™è£¡å¯¦ä½œ LSTMã€Transformer æˆ–å…¶ä»–æ·±åº¦å­¸ç¿’æ¨¡å‹ã€‚
    """
    
    def __init__(self, model_path: str):
        super().__init__(model_path)
        self.model = None
    
    def load_model(self) -> bool:
        """è¼‰å…¥è¨“ç·´å¥½çš„æ¨¡å‹"""
        # TODO: å¯¦ä½œæ¨¡å‹è¼‰å…¥
        # ä¾‹å¦‚ï¼šself.model = torch.load(self.model_path)
        print(f"TODO: è¼‰å…¥æ¨¡å‹ {self.model_path}")
        return False
    
    def predict(self, landmarks: np.ndarray) -> Dict[str, Any]:
        """ä½¿ç”¨æ¨¡å‹é æ¸¬"""
        if not self.is_loaded:
            raise RuntimeError("æ¨¡å‹å°šæœªè¼‰å…¥")
        
        # TODO: å¯¦ä½œæ¨¡å‹é æ¸¬
        # ä¾‹å¦‚ï¼š
        # features = self.preprocess(landmarks)
        # output = self.model(features)
        # gesture = self.decode_output(output)
        
        return {
            'gesture': "æœªå¯¦ä½œ",
            'confidence': 0.0,
            'details': {}
        }
